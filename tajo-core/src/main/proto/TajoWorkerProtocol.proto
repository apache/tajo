/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// TajoMaster -> TajoWorker, TajoWorker(QueryMaster) <-> TajoWorker Protocol
option java_package = "org.apache.tajo.ipc";
option java_outer_classname = "TajoWorkerProtocol";
option java_generic_services = true;
option java_generate_equals_and_hash = true;

import "yarn_protos.proto";
import "tajo_protos.proto";
import "TajoIdProtos.proto";
import "CatalogProtos.proto";
import "PrimitiveProtos.proto";

message SessionProto {
  required string session_id = 1;
  required string username = 2;
  required string current_database = 3;
  required int64 last_access_time = 4;
  required KeyValueSetProto variables = 5;
}

message TaskStatusProto {
  required QueryUnitAttemptIdProto id = 1;
  required string workerName = 2;
  required float progress = 3;
  required TaskAttemptState state = 4;
  optional StatSetProto stats = 5;
  optional TableStatsProto inputStats = 6;
  optional TableStatsProto resultStats = 7;
  repeated ShuffleFileOutput shuffleFileOutputs = 8;
}

message TaskCompletionReport {
  required QueryUnitAttemptIdProto id = 1;
  optional StatSetProto stats = 2;
  optional TableStatsProto inputStats = 3;
  optional TableStatsProto resultStats = 4;
  repeated ShuffleFileOutput shuffleFileOutputs = 5;
}

message TaskFatalErrorReport {
  required QueryUnitAttemptIdProto id = 1;
  optional string errorMessage = 2;
  optional string errorTrace = 3;
}

message QueryUnitRequestProto {
    required QueryUnitAttemptIdProto id = 1;
    repeated FragmentProto fragments = 2;
    required string outputTable = 3;
    required bool clusteredOutput = 4;
    required string serializedData = 5;
    optional bool interQuery = 6 [default = false];
    repeated FetchProto fetches = 7;
    optional bool shouldDie = 8;
    optional KeyValueSetProto queryContext = 9;
    optional DataChannelProto dataChannel = 10;
    optional EnforcerProto enforcer = 11;
}

message FetchProto {
    required string host = 1;
    required int32 port = 2;
    required ShuffleType type = 3;
    required ExecutionBlockIdProto executionBlockId = 4;
    required int32 partitionId = 5;
    required string name = 6;
    optional string rangeParams = 7;
    optional bool hasNext = 8 [default = false];

    //repeated part
    repeated int32 taskId = 9 [packed=true];
    repeated int32 attemptId = 10 [packed=true];
}



message QueryUnitResponseProto {
    required string id = 1;
    required QueryState status = 2;
}

message StatusReportProto {
  required int64 timestamp = 1;
  required string serverName = 2;
  repeated TaskStatusProto status = 3;
  repeated QueryUnitAttemptIdProto pings = 4;
}

message CommandRequestProto {
    repeated Command command = 1;
}

message CommandResponseProto {
}

message Command {
    required QueryUnitAttemptIdProto id = 1;
    required CommandType type = 2;
}

enum CommandType {
    PREPARE = 0;
    LAUNCH = 1;
    STOP = 2;
    FINALIZE = 3;
}

message ShuffleFileOutput {
    required int32 partId = 1;
    optional string fileName = 2;
}

message QueryExecutionRequestProto {
    required QueryIdProto queryId = 1;
    required SessionProto session = 2;
    required KeyValueSetProto queryContext = 3;
    required StringProto exprInJson = 5;
    optional StringProto logicalPlanJson = 6;
}

message GetTaskRequestProto {
    required hadoop.yarn.ContainerIdProto containerId = 1;
    required ExecutionBlockIdProto executionBlockId = 2;
}

enum ShuffleType {
  NONE_SHUFFLE = 0;
  HASH_SHUFFLE = 1;
  RANGE_SHUFFLE = 2;
}

enum TransmitType {
  PUSH_TRANSMIT = 0;
  PULL_TRANSMIT = 1;
  FILE_WRITE = 2;
}

message DataChannelProto {
  required ExecutionBlockIdProto srcId = 1;
  required ExecutionBlockIdProto targetId = 2;

  required TransmitType transmitType = 3 [default = PULL_TRANSMIT];
  required ShuffleType shuffleType = 4;

  optional SchemaProto schema = 5;

  repeated ColumnProto shuffleKeys = 7;
  optional int32 numOutputs = 9 [default = 1];

  optional StoreType storeType = 10 [default = CSV];
}

message RunExecutionBlockRequestProto {
    required string executionBlockId = 1;
    required string queryMasterHost = 2;
    required int32 queryMasterPort = 3;
    required string nodeId = 4;
    required string containerId = 5;
    optional string queryOutputPath = 6;
}

service TajoWorkerProtocolService {
  rpc ping (QueryUnitAttemptIdProto) returns (BoolProto);

  // from QueryMaster(Worker)
  rpc executeExecutionBlock(RunExecutionBlockRequestProto) returns (BoolProto);
  rpc killTaskAttempt(QueryUnitAttemptIdProto) returns (BoolProto);
  rpc cleanup(QueryIdProto) returns (BoolProto);
}

message EnforceProperty {
  enum EnforceType {
    SORTED_INPUT = 0;
    OUTPUT_DISTINCT = 1;
    GROUP_BY = 2;
    JOIN = 3;
    SORT = 4;
    BROADCAST = 5;
    COLUMN_PARTITION = 6;
    DISTINCT_GROUP_BY = 7;
  }

  // Identifies which field is filled in.
  required EnforceType type = 1;

  // One of the following will be filled in.
  optional SortedInputEnforce sortedInput = 2;
  optional OutputDistinctEnforce outputDistinct = 3;
  optional GroupbyEnforce groupby = 4;
  optional JoinEnforce join = 5;
  optional SortEnforce sort = 6;
  optional BroadcastEnforce broadcast = 7;
  optional ColumnPartitionEnforcer columnPartition = 8;
  optional DistinctGroupbyEnforcer distinct = 9;
}

message SortedInputEnforce {
  required string tableName = 1;
  repeated SortSpecProto sortSpecs = 2;
}

message OutputDistinctEnforce {
}

message JoinEnforce {
  enum JoinAlgorithm {
    NESTED_LOOP_JOIN = 0;
    BLOCK_NESTED_LOOP_JOIN = 1;
    IN_MEMORY_HASH_JOIN = 2;
    HYBRID_HASH_JOIN = 3;
    MERGE_JOIN = 4;
  }

  required int32 pid = 1;
  required JoinAlgorithm algorithm = 2;
}

message GroupbyEnforce {
  enum GroupbyAlgorithm {
    HASH_AGGREGATION = 0;
    SORT_AGGREGATION = 1;
  }

  required int32 pid = 1;
  required GroupbyAlgorithm algorithm = 2;
  repeated SortSpecProto sortSpecs = 3;
}

message SortEnforce {
  enum SortAlgorithm {
    IN_MEMORY_SORT = 0;
    MERGE_SORT = 1;
  }

  required int32 pid = 1;
  required SortAlgorithm algorithm = 2;
}

message BroadcastEnforce {
  required string tableName = 1;
}

message ColumnPartitionEnforcer {
  enum ColumnPartitionAlgorithm {
    HASH_PARTITION = 0;
    SORT_PARTITION = 1;
  }

  required int32 pid = 1;
  required ColumnPartitionAlgorithm algorithm = 2;
}

message DistinctGroupbyEnforcer {
  enum DistinctAggregationAlgorithm {
    HASH_AGGREGATION = 0;
    SORT_AGGREGATION = 1;
  }

  message SortSpecArray {
    required int32 pid = 1;
    repeated SortSpecProto sortSpecs = 2;
  }
  required int32 pid = 1;
  required DistinctAggregationAlgorithm algorithm = 2;
  repeated SortSpecArray sortSpecArrays = 3;
}

message EnforcerProto {
  repeated EnforceProperty properties = 1;
}

message FetcherHistoryProto {
  required int64 startTime = 1;
  optional int64 finishTime = 2;
  required FetcherState state = 3;
  required int64 fileLength = 4;
  required int32 messageReceivedCount = 5;
}

message TaskHistoryProto {
  required QueryUnitAttemptIdProto queryUnitAttemptId = 1;
  required TaskAttemptState state = 2;
  required float progress = 3;
  required int64 startTime = 4;
  required int64 finishTime = 5;
  required TableStatsProto inputStats = 6;
  optional TableStatsProto outputStats = 7;
  optional string outputPath = 8;
  optional string workingPath = 9;
  optional int32 finishedFetchCount = 10;
  optional int32 totalFetchCount = 11;
  repeated FetcherHistoryProto fetcherHistories = 12;
}

message TaskRunnerHistoryProto {
  required ExecutionBlockIdProto executionBlockId = 1;
  required string state = 2;
  required string containerId = 3;
  optional int64 startTime = 4;
  optional int64 finishTime = 5;
  repeated TaskHistoryProto taskHistories = 6;
}