/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.tajo.engine.planner;

import com.google.common.base.Preconditions;
import com.google.common.collect.Lists;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.hadoop.fs.Path;
import org.apache.tajo.algebra.*;
import org.apache.tajo.algebra.CreateTable.ColumnDefinition;
import org.apache.tajo.catalog.*;
import org.apache.tajo.catalog.function.AggFunction;
import org.apache.tajo.catalog.function.GeneralFunction;
import org.apache.tajo.catalog.proto.CatalogProtos;
import org.apache.tajo.common.TajoDataTypes;
import org.apache.tajo.common.TajoDataTypes.DataType;
import org.apache.tajo.datum.Datum;
import org.apache.tajo.datum.DatumFactory;
import org.apache.tajo.engine.eval.*;
import org.apache.tajo.engine.eval.EvalType;
import org.apache.tajo.engine.planner.LogicalPlan.QueryBlock;
import org.apache.tajo.engine.planner.logical.*;
import org.apache.tajo.engine.query.exception.InvalidQueryException;
import org.apache.tajo.engine.query.exception.UndefinedFunctionException;
import org.apache.tajo.engine.utils.SchemaUtil;
import org.apache.tajo.exception.InternalException;

import java.util.List;
import java.util.Stack;

import static org.apache.tajo.algebra.Aggregation.GroupType;

/**
 * This class creates a logical plan from a parse tree ({@link org.apache.tajo.engine.parser.SQLAnalyzer})
 * generated by {@link org.apache.tajo.engine.parser.SQLAnalyzer}.
 *
 * Relational operators can be divided into two categories as follows:
 * <oi>
 *  <li>General operator: this type operators do not affect the tuple schema.
 *  Selection, Sort, and Limit belong to this type.</li>
 *  <li>Projectable operator: this type operators affects the tuple schema.
 *  Scan, Groupby, and Join belong to this type.
 *  </li>
 * </oi>
 */
public class LogicalPlanner extends BaseAlgebraVisitor<LogicalPlanner.PlanContext, LogicalNode> {
  private static Log LOG = LogFactory.getLog(LogicalPlanner.class);
  private final CatalogService catalog;

  public LogicalPlanner(CatalogService catalog) {
    this.catalog = catalog;
  }

  public static class PlanContext {
    LogicalPlan plan;
    QueryBlock block;

    public PlanContext(LogicalPlan plan, QueryBlock block) {
      this.plan = plan;
      this.block = block;
    }
  }

  /**
   * This generates a logical plan.
   *
   * @param expr A relational algebraic expression for a query.
   * @return A logical plan
   */
  public LogicalPlan createPlan(Expr expr) {

    LogicalPlan plan = new LogicalPlan(this);
    LogicalNode subroot = null;

    Stack<OpType> stack =new Stack<OpType>();

    QueryBlock rootBlock = plan.newAndGetBlock(LogicalPlan.ROOT_BLOCK);
    PlanContext context = new PlanContext(plan, rootBlock);
    try {
      subroot = visitChild(context, stack, expr);
    } catch (PlanningException e) {
      e.printStackTrace();
    }

    LogicalRootNode root = new LogicalRootNode();
    root.setInSchema(subroot.getOutSchema());
    root.setOutSchema(subroot.getOutSchema());
    root.setChild(subroot);
    plan.getRootBlock().setRoot(root);

    return plan;
  }

  public void preHook(PlanContext context, Stack<OpType> stack, Expr expr) {
    context.block = checkNewBlockAndGet(context.plan, context.block.getName());
  }

  public LogicalNode postHook(PlanContext context, Stack<OpType> stack, Expr expr, LogicalNode current)
      throws PlanningException {
    // == Post work ==
    if (expr.getType() == OpType.RelationList && ((RelationList) expr).size() == 1) {
      return current;
    }

    // mark the node as the visited node and do post work for each operator
    context.plan.postVisit(context.block.getName(), current, stack);
    // check and set evaluated targets and update in/out schemas
    context.block.checkAndSetEvaluatedTargets(current);

    return current;
  }

  /**
   * It checks if the first node in this query block. If not, it creates and adds a new query block.
   * In addition, it always returns the query block corresponding to the block name.
   */
  private QueryBlock checkNewBlockAndGet(LogicalPlan plan, String blockName) {
    QueryBlock block = plan.getBlock(blockName);
    if (block == null) {
      return plan.newAndGetBlock(blockName);
    } else {
      return block;
    }
  }

  @Override
  public ScanNode visitRelation(PlanContext context, Stack<OpType> stack, Relation expr)
      throws VerifyException {
    // 1. init phase

    // 2. build child plans
    // 3. build scan plan
    Relation relation = (Relation) expr;
    TableDesc desc = catalog.getTableDesc(relation.getName());
    FromTable fromTable = new FromTable(desc);

    if (relation.hasAlias()) {
      fromTable.setAlias(relation.getAlias());
    }

    ScanNode scanNode = new ScanNode(fromTable);

    return scanNode;
  }

  /*===============================================================================================
    JOIN SECTION
   ===============================================================================================*/
  @Override
  public LogicalNode visitRelationList(PlanContext context, Stack<OpType> stack, RelationList relations)
      throws PlanningException {

    LogicalNode current = visitChild(context, stack, relations.getRelations()[0]);

    LogicalNode left;
    LogicalNode right;
    if (relations.size() > 1) {

      for (int i = 1; i < relations.size(); i++) {
        left = current;
        right = visitChild(context, stack, relations.getRelations()[i]);
        current = createCatasianProduct(left, right);
      }
    }

    return current;
  }

  @Override
  public LogicalNode visitJoin(PlanContext context, Stack<OpType> stack, Join join)
      throws PlanningException {
    // Phase 1: Init
    LogicalPlan plan = context.plan;
    QueryBlock block = context.block;

    // Phase 2: build child plans
    stack.push(OpType.Join);
    LogicalNode left = visitChild(context, stack, join.getLeft());
    LogicalNode right = visitChild(context, stack, join.getRight());
    stack.pop();

    // Phase 3: build this plan
    JoinNode joinNode = new JoinNode(join.getJoinType(), left, right);

    // Set A merged input schema
    Schema merged;
    if (join.isNatural()) {
      merged = getNaturalJoin(left, right);
    } else {
      merged = SchemaUtil.merge(left.getOutSchema(), right.getOutSchema());
    }
    joinNode.setInSchema(merged);
    joinNode.setOutSchema(merged);

    // Determine join conditions
    if (join.isNatural()) { // if natural join, it should have the equi-join conditions by common column names
      Schema leftSchema = joinNode.getLeftChild().getInSchema();
      Schema rightSchema = joinNode.getRightChild().getInSchema();
      Schema commons = SchemaUtil.getCommons(leftSchema, rightSchema);
      EvalNode njCond = getNaturalJoinCondition(leftSchema, rightSchema, commons);
      joinNode.setJoinQual(njCond);
    } else if (join.hasQual()) { // otherwise, the given join conditions are set
      joinNode.setJoinQual(createEvalTree(plan, block.getName(), join.getQual()));
    }

    return joinNode;
  }

  private static EvalNode getNaturalJoinCondition(Schema outer, Schema inner, Schema commons) {
    EvalNode njQual = null;
    EvalNode equiQual;

    Column leftJoinKey;
    Column rightJoinKey;
    for (Column common : commons.getColumns()) {
      leftJoinKey = outer.getColumnByName(common.getColumnName());
      rightJoinKey = inner.getColumnByName(common.getColumnName());
      equiQual = new BinaryEval(EvalType.EQUAL,
          new FieldEval(leftJoinKey), new FieldEval(rightJoinKey));
      if (njQual == null) {
        njQual = equiQual;
      } else {
        njQual = new BinaryEval(EvalType.AND,
            njQual, equiQual);
      }
    }

    return njQual;
  }

  private static LogicalNode createCatasianProduct(LogicalNode left, LogicalNode right) {
    JoinNode join = new JoinNode(JoinType.CROSS, left, right);
    Schema joinSchema = SchemaUtil.merge(
        join.getLeftChild().getOutSchema(),
        join.getRightChild().getOutSchema());
    join.setInSchema(joinSchema);
    join.setOutSchema(joinSchema);

    return join;
  }

  private static Schema getNaturalJoin(LogicalNode outer, LogicalNode inner) {
    Schema joinSchema = new Schema();
    Schema commons = SchemaUtil.getCommons(outer.getOutSchema(),
        inner.getOutSchema());
    joinSchema.addColumns(commons);
    for (Column c : outer.getOutSchema().getColumns()) {
      for (Column common : commons.getColumns()) {
        if (!common.getColumnName().equals(c.getColumnName())) {
          joinSchema.addColumn(c);
        }
      }
    }

    for (Column c : inner.getOutSchema().getColumns()) {
      for (Column common : commons.getColumns()) {
        if (!common.getColumnName().equals(c.getColumnName())) {
          joinSchema.addColumn(c);
        }
      }
    }
    return joinSchema;
  }

  /*===============================================================================================
    SET OPERATION SECTION
   ===============================================================================================*/

  @Override
  public LogicalNode visitUnion(PlanContext context, Stack<OpType> stack, SetOperation setOperation)
      throws PlanningException {
    return buildSetPlan(context, stack, setOperation);
  }

  @Override
  public LogicalNode visitExcept(PlanContext context, Stack<OpType> stack, SetOperation setOperation)
      throws PlanningException {
    return buildSetPlan(context, stack, setOperation);
  }

  @Override
  public LogicalNode visitIntersect(PlanContext context, Stack<OpType> stack, SetOperation setOperation)
      throws PlanningException {
    return buildSetPlan(context, stack, setOperation);
  }

  private LogicalNode buildSetPlan(PlanContext context, Stack<OpType> stack, SetOperation setOperation)
      throws PlanningException {

    // 1. Init Phase
    LogicalPlan plan = context.plan;
    QueryBlock block = context.block;

    // 2. Build Child Plans
    PlanContext leftContext = new PlanContext(plan, plan.newAnonymousBlock());
    Stack<OpType> leftStack = new Stack<OpType>();
    LogicalNode left = visitChild(leftContext, leftStack, setOperation.getLeft());

    PlanContext rightContext = new PlanContext(plan, plan.newAnonymousBlock());
    Stack<OpType> rightStack = new Stack<OpType>();
    LogicalNode right = visitChild(rightContext, rightStack, setOperation.getRight());

    verifySetStatement(setOperation.getType(), leftContext.block, rightContext.block);

    BinaryNode setOp;
    if (setOperation.getType() == OpType.Union) {
      setOp = new UnionNode(left, right);
    } else if (setOperation.getType() == OpType.Except) {
      setOp = new ExceptNode(left, right);
    } else if (setOperation.getType() == OpType.Intersect) {
      setOp = new IntersectNode(left, right);
    } else {
      throw new VerifyException(setOperation.toJson());
    }

    // Strip the table names from the targets of the both blocks
    // in order to check the equivalence the schemas of both blocks.
    Target [] leftStrippedTargets = PlannerUtil.stripTarget(leftContext.block.getCurrentTargets());

    Schema outSchema = PlannerUtil.targetToSchema(leftStrippedTargets);
    setOp.setInSchema(left.getOutSchema());
    setOp.setOutSchema(outSchema);
    setOp.setLeftChild(left);
    setOp.setRightChild(right);

    if (isNoUpperProjection(stack)) {
      block.targetListManager = new TargetListManager(plan, leftStrippedTargets);
      block.targetListManager.setEvaluatedAll();
      block.targetListManager.getUpdatedTarget();
      block.setSchema(block.targetListManager.getUpdatedSchema());
    }

    return setOp;
  }

  private boolean verifySetStatement(OpType type, QueryBlock left, QueryBlock right)
      throws VerifyException {

    if (left.getCurrentTargets().length != right.getCurrentTargets().length) {
      throw new VerifyException("ERROR: each " + type.name() + " query must have the same number of columns");
    }

    Target[] targets1 = left.getCurrentTargets();
    Target[] targets2 = right.getCurrentTargets();

    for (int i = 0; i < targets1.length; i++) {
      if (!targets1[i].getDataType().equals(targets2[i].getDataType())) {
        throw new VerifyException("UNION types " + targets1[i].getDataType().getType() + " and "
            + targets2[i].getDataType().getType() + " cannot be matched");
      }
    }

    return true;
  }

  @Override
  public SelectionNode visitFilter(PlanContext context, Stack<OpType> stack, Selection selection)
      throws PlanningException {
    // 1. init phase:
    LogicalPlan plan = context.plan;
    QueryBlock block = context.block;

    // 2. build child plans:
    stack.push(OpType.Filter);
    LogicalNode child = visitChild(context, stack, selection.getChild());
    stack.pop();

    // 3. build this plan:
    EvalNode searchCondition = createEvalTree(plan, block.getName(), selection.getQual());
    SelectionNode selectionNode = new SelectionNode(searchCondition);

    // 4. set child plan, update input/output schemas:
    selectionNode.setChild(child);
    selectionNode.setInSchema(child.getOutSchema());
    selectionNode.setOutSchema(child.getOutSchema());

    // 5. update block information:
    block.setSelectionNode(selectionNode);

    return selectionNode;
  }

  /*===============================================================================================
    GROUP BY SECTION
   ===============================================================================================*/

  @Override
  public LogicalNode visitGroupBy(PlanContext context, Stack<OpType> stack, Aggregation aggregation)
      throws PlanningException {

    // 1. Initialization Phase:
    LogicalPlan plan = context.plan;
    QueryBlock block = context.block;

    // 2. Build Child Plan Phase:
    stack.push(OpType.Aggregation);
    LogicalNode child = visitChild(context, stack, aggregation.getChild());
    stack.pop();

    // 3. Build This Plan:
    Aggregation.GroupElement [] groupElements = aggregation.getGroupSet();

    if (groupElements[0].getType() == GroupType.OrdinaryGroup) { // for group-by
      GroupElement annotatedElements [] = new GroupElement[groupElements.length];
      for (int i = 0; i < groupElements.length; i++) {
        annotatedElements[i] = new GroupElement(
            groupElements[i].getType(),
            annotateGroupingColumn(plan, block.getName(), groupElements[i].getColumns(), child));
      }
      GroupbyNode groupingNode = new GroupbyNode(annotatedElements[0].getColumns());
      if (aggregation.hasHavingCondition()) {
        groupingNode.setHavingCondition(
            createEvalTree(plan, block.getName(), aggregation.getHavingCondition()));
      }

      // 4. Set Child Plan and Update Input Schemes Phase
      groupingNode.setChild(child);
      block.setGroupingNode(groupingNode);
      groupingNode.setInSchema(child.getInSchema());

      // 5. Update Output Schema and Targets for Upper Plan

      return groupingNode;

    } else if (groupElements[0].getType() == GroupType.Cube) { // for cube by
      List<Column[]> cuboids  = generateCuboids(annotateGroupingColumn(plan, block.getName(),
          groupElements[0].getColumns(), child));
      UnionNode topUnion = createGroupByUnion(plan, block, child, cuboids, 0);
      block.resolveGrouping();
      block.getTargetListManager().setEvaluatedAll();

      return topUnion;
    } else {
      throw new InvalidQueryException("Not support grouping");
    }
  }

  private UnionNode createGroupByUnion(final LogicalPlan plan,
                                       final QueryBlock block,
                                       final LogicalNode subNode,
                                       final List<Column[]> cuboids,
                                       final int idx) {
    UnionNode union;
    try {
      if ((cuboids.size() - idx) > 2) {
        GroupbyNode g1 = new GroupbyNode(cuboids.get(idx));
        Target[] clone = cloneTargets(block.getCurrentTargets());

        g1.setTargets(clone);
        g1.setChild((LogicalNode) subNode.clone());
        g1.setInSchema(g1.getChild().getOutSchema());
        Schema outSchema = getProjectedSchema(plan, block.getCurrentTargets());
        g1.setOutSchema(outSchema);

        LogicalNode right = createGroupByUnion(plan, block, subNode, cuboids, idx+1);
        union = new UnionNode(g1, right);
        union.setInSchema(g1.getOutSchema());
        union.setOutSchema(g1.getOutSchema());

        return union;
      } else {
        GroupbyNode g1 = new GroupbyNode(cuboids.get(idx));
        Target[] clone = cloneTargets(block.getCurrentTargets());
        g1.setTargets(clone);
        g1.setChild((LogicalNode) subNode.clone());
        g1.setInSchema(g1.getChild().getOutSchema());
        Schema outSchema = getProjectedSchema(plan, clone);
        g1.setOutSchema(outSchema);

        GroupbyNode g2 = new GroupbyNode(cuboids.get(idx+1));
        clone = cloneTargets(block.getCurrentTargets());
        g2.setTargets(clone);
        g2.setChild((LogicalNode) subNode.clone());
        g2.setInSchema(g1.getChild().getOutSchema());
        outSchema = getProjectedSchema(plan, clone);
        g2.setOutSchema(outSchema);
        union = new UnionNode(g1, g2);
        union.setInSchema(g1.getOutSchema());
        union.setOutSchema(g1.getOutSchema());

        return union;
      }
    } catch (CloneNotSupportedException cnse) {
      LOG.error(cnse);
      throw new InvalidQueryException(cnse);
    }
  }

  /**
   * It transforms a list of column references into a list of annotated columns with considering aliased expressions.
   */
  private Column[] annotateGroupingColumn(LogicalPlan plan, String blockName,
                                           ColumnReferenceExpr[] columnRefs, LogicalNode child)
      throws VerifyException {
    Column[] columns = new Column[columnRefs.length];
    for (int i = 0; i < columnRefs.length; i++) {
      columns[i] = plan.findColumnFromChildNode(columnRefs[i], blockName, child);
    }

    return columns;
  }

  private static Target[] cloneTargets(Target[] sourceTargets)
      throws CloneNotSupportedException {
    Target[] clone = new Target[sourceTargets.length];
    for (int i = 0; i < sourceTargets.length; i++) {
      clone[i] = (Target) sourceTargets[i].clone();
    }

    return clone;
  }

  public static final Column[] ALL= Lists.newArrayList().toArray(new Column[0]);

  public static List<Column[]> generateCuboids(Column[] columns) {
    int numCuboids = (int) Math.pow(2, columns.length);
    int maxBits = columns.length;

    List<Column[]> cube = Lists.newArrayList();
    List<Column> cuboidCols;

    cube.add(ALL);
    for (int cuboidId = 1; cuboidId < numCuboids; cuboidId++) {
      cuboidCols = Lists.newArrayList();
      for (int j = 0; j < maxBits; j++) {
        int bit = 1 << j;
        if ((cuboidId & bit) == bit) {
          cuboidCols.add(columns[j]);
        }
      }
      cube.add(cuboidCols.toArray(new Column[cuboidCols.size()]));
    }
    return cube;
  }

  /*===============================================================================================
    SORT SECTION
   ===============================================================================================*/

  @Override
  public SortNode visitSort(PlanContext context, Stack<OpType> stack, Sort sort) throws PlanningException {

    // 1. Initialization Phase:
    LogicalPlan plan = context.plan;
    QueryBlock block = context.block;

    // 2. Build Child Plans:
    stack.push(OpType.Sort);
    LogicalNode child = visitChild(context, stack, sort.getChild());
    child = insertGroupingIfUnresolved(plan, block.getName(), child, stack);
    stack.pop();

    // 3. Build this plan:
    SortSpec[] annotatedSortSpecs = new SortSpec[sort.getSortSpecs().length];
    Column column;
    Sort.SortSpec[] sortSpecs = sort.getSortSpecs();
    for (int i = 0; i < sort.getSortSpecs().length; i++) {
      column = plan.findColumnFromChildNode(sortSpecs[i].getKey(), block.getName(), child);
      annotatedSortSpecs[i] = new SortSpec(column, sortSpecs[i].isAscending(),
          sortSpecs[i].isNullFirst());
    }
    SortNode sortNode = new SortNode(annotatedSortSpecs);

    // 4. Set Child Plan, Update Input/Output Schemas:
    sortNode.setChild(child);
    sortNode.setInSchema(child.getOutSchema());
    sortNode.setOutSchema(child.getOutSchema());

    return sortNode;
  }

  @Override
  public LimitNode visitLimit(PlanContext context, Stack<OpType> stack, Limit limit) throws PlanningException {
    // 1. Init Phase:
    LogicalPlan plan = context.plan;
    QueryBlock block = context.block;

    // build child plans
    stack.push(OpType.Limit);
    LogicalNode child = visitChild(context, stack, limit.getChild());
    stack.pop();

    // build limit plan
    EvalNode firstFetchNum = createEvalTree(plan, block.getName(), limit.getFetchFirstNum());
    firstFetchNum.eval(null, null, null);
    LimitNode limitNode = new LimitNode(firstFetchNum.terminate(null).asInt8());

    // set child plan and update input/output schemas.
    limitNode.setChild(child);
    limitNode.setInSchema(child.getOutSchema());
    limitNode.setOutSchema(child.getOutSchema());
    return limitNode;
  }

  /*===============================================================================================
    PROJECTION SECTION
   ===============================================================================================*/

  @Override
  public LogicalNode visitProjection(PlanContext context, Stack<OpType> stack, Projection projection)
      throws PlanningException {

    //1: init Phase
    LogicalPlan plan = context.plan;
    QueryBlock block = context.block;

    block.setProjection(projection);
    if (!projection.isAllProjected()) {
      block.targetListManager = new TargetListManager(plan, projection.size());
    }

    if (!projection.hasChild()) {
      EvalExprNode evalOnly =
          new EvalExprNode(annotateTargets(plan, block.getName(), projection.getTargets()));
      evalOnly.setOutSchema(getProjectedSchema(plan, evalOnly.getExprs()));
      block.setProjectionNode(evalOnly);
      for (int i = 0; i < evalOnly.getTargets().length; i++) {
        block.targetListManager.updateTarget(i, evalOnly.getTargets()[i]);
      }
      return evalOnly;
    }

    // 2: Build Child Plans
    stack.push(OpType.Projection);
    LogicalNode child = visitChild(context, stack, projection.getChild());
    child = insertGroupingIfUnresolved(plan, block.getName(), child, stack);
    stack.pop();

    // All targets must be evaluable before the projection.
    Preconditions.checkState(block.getTargetListManager().isAllEvaluated(),
        "Some targets cannot be evaluated in the query block \"%s\"", block.getName());

    ProjectionNode projectionNode;
    if (projection.isAllProjected()) {
      projectionNode = new ProjectionNode(PlannerUtil.schemaToTargets(child.getOutSchema()));
    } else {
      projectionNode = new ProjectionNode(block.getCurrentTargets());
    }

    block.setProjectionNode(projectionNode);
    projectionNode.setOutSchema(getProjectedSchema(plan, projectionNode.getTargets()));
    projectionNode.setInSchema(child.getOutSchema());
    projectionNode.setChild(child);

    if (projection.isDistinct() && block.hasGrouping()) {
      throw new VerifyException("Cannot support grouping and distinct at the same time");
    } else {
      if (projection.isDistinct()) {
        Schema outSchema = projectionNode.getOutSchema();
        GroupbyNode dupRemoval = new GroupbyNode(outSchema.toArray());
        dupRemoval.setTargets(block.getTargetListManager().getTargets());
        dupRemoval.setInSchema(child.getOutSchema());
        dupRemoval.setOutSchema(outSchema);
        dupRemoval.setChild(child);
        projectionNode.setChild(dupRemoval);
      }
    }

    return projectionNode;
  }

  /**
   * Insert a group-by operator before a sort or a projection operator.
   * It is used only when a group-by clause is not given.
   */
  private LogicalNode insertGroupingIfUnresolved(LogicalPlan plan, String blockName,
                                                 LogicalNode child, Stack<OpType> stack) throws PlanningException {
    QueryBlock block = plan.getBlock(blockName);
    if (!block.isGroupingResolved()) {
      GroupbyNode groupbyNode = new GroupbyNode(new Column[] {});
      groupbyNode.setTargets(block.getCurrentTargets());
      groupbyNode.setChild(child);
      groupbyNode.setInSchema(child.getOutSchema());

      plan.postVisit(blockName, groupbyNode, stack);
      block.checkAndSetEvaluatedTargets(groupbyNode);
      return groupbyNode;
    } else {
      return child;
    }
  }

  private boolean isNoUpperProjection(Stack<OpType> stack) {
    for (OpType node : stack) {
      if (!( (node == OpType.Projection) || (node == OpType.Aggregation) || (node == OpType.Join) )) {
        return false;
      }
    }

    return true;
  }

  /*===============================================================================================
    Data Definition Language (DDL) SECTION
   ===============================================================================================*/

  @Override
  public LogicalNode visitCreateTable(PlanContext context, Stack<OpType> stack, CreateTable expr)
      throws PlanningException {

     String tableName = expr.getTableName();

    if (expr.hasSubQuery()) {
      stack.add(OpType.CreateTable);
      LogicalNode subQuery = visitChild(context, stack, expr.getSubQuery());
      stack.pop();
      StoreTableNode storeNode = new StoreTableNode(tableName);
      storeNode.setChild(subQuery);

      if (expr.hasTableElements()) {
        Schema schema = convertTableElementsSchema(expr.getTableElements());
        storeNode.setOutSchema(schema);
      } else {
        storeNode.setOutSchema(subQuery.getOutSchema());
      }
      storeNode.setInSchema(subQuery.getOutSchema());

      if (expr.hasStorageType()) {
        storeNode.setStorageType(CatalogUtil.getStoreType(expr.getStorageType()));
      } else {
        // default type
        // TODO - it should be configurable.
        storeNode.setStorageType(CatalogProtos.StoreType.CSV);
      }

      if (expr.hasParams()) {
        Options options = new Options();
        options.putAll(expr.getParams());
        storeNode.setOptions(options);
      }

      return storeNode;
    } else {
      CreateTableNode createTableNode = new CreateTableNode(expr.getTableName(),
          convertTableElementsSchema(expr.getTableElements()));

      if (expr.isExternal()) {
        createTableNode.setExternal(true);
      }

      if (expr.hasStorageType()) {
        createTableNode.setStorageType(CatalogUtil.getStoreType(expr.getStorageType()));
      } else {
        // default type
        // TODO - it should be configurable.
        createTableNode.setStorageType(CatalogProtos.StoreType.CSV);
      }
      if (expr.hasParams()) {
        Options options = new Options();
        options.putAll(expr.getParams());
        createTableNode.setOptions(options);
      }

      if (expr.hasLocation()) {
        createTableNode.setPath(new Path(expr.getLocation()));
      }

      return createTableNode;
    }
  }



  /**
   * It transforms table definition elements to schema.
   *
   * @param elements to be transformed
   * @return schema transformed from table definition elements
   */
  private Schema convertTableElementsSchema(CreateTable.ColumnDefinition [] elements) {
    Schema schema = new Schema();

    for (CreateTable.ColumnDefinition columnDefinition: elements) {
      schema.addColumn(convertColumn(columnDefinition));
    }

    return schema;
  }

  private Column convertColumn(ColumnDefinition columnDefinition) {
    TajoDataTypes.Type type = TajoDataTypes.Type.valueOf(columnDefinition.getDataType());
    Column column;
    switch (type) {
      case CHAR:
      case VARCHAR:
      case NCHAR:
      case NVARCHAR:
        column = new Column(columnDefinition.getColumnName(),
            TajoDataTypes.Type.valueOf(columnDefinition.getDataType()),
            columnDefinition.getLengthOrPrecision());
        break;
      case FLOAT4:
      case FLOAT8:
        // TODO: support precision
        column = new Column(columnDefinition.getColumnName(),
            TajoDataTypes.Type.valueOf(columnDefinition.getDataType()));
        break;
      case NUMERIC:
      case DECIMAL:
        // TODO: support precision and scale
        column = new Column(columnDefinition.getColumnName(),
            TajoDataTypes.Type.valueOf(columnDefinition.getDataType()));
        break;
      default:
        column = new Column(columnDefinition.getColumnName(),
            TajoDataTypes.Type.valueOf(columnDefinition.getDataType()));
    }
    return column;
  }

  @Override
  public LogicalNode visitDropTable(PlanContext context, Stack<OpType> stack, DropTable dropTable) {
    DropTableNode dropTableNode = new DropTableNode(dropTable.getTableName());
    return dropTableNode;
  }

  /*===============================================================================================
    Expression SECTION
   ===============================================================================================*/

  public EvalNode createEvalTree(LogicalPlan plan, String blockName, final Expr expr)
      throws VerifyException {
    switch(expr.getType()) {

      // constants
      case Literal:
        LiteralValue literal = (LiteralValue) expr;
        switch (literal.getValueType()) {
          case String:
            return new ConstEval(DatumFactory.createText(literal.getValue()));
          case Unsigned_Integer:
            return new ConstEval(DatumFactory.createInt4(literal.getValue()));
          case Unsigned_Large_Integer:
            return new ConstEval(DatumFactory.createInt8(literal.getValue()));
          case Unsigned_Float:
            return new ConstEval(DatumFactory.createFloat4(literal.getValue()));
          default:
            throw new RuntimeException("Unsupported type: " + literal.getValueType());
        }

      case ValueList: {
        ValueListExpr valueList = (ValueListExpr) expr;
        Datum[] values = new Datum[valueList.getValues().length];
        ConstEval [] constEvals = new ConstEval[valueList.getValues().length];
        for (int i = 0; i < valueList.getValues().length; i++) {
          constEvals[i] = (ConstEval) createEvalTree(plan, blockName, valueList.getValues()[i]);
          values[i] = constEvals[i].getValue();
        }
        return new RowConstant(values);
      }

        // unary expression
      case Not:
        NotExpr notExpr = (NotExpr) expr;
        return new NotEval(createEvalTree(plan, blockName, notExpr.getChild()));

      // binary expressions
      case LikePredicate:
        LikePredicate like = (LikePredicate) expr;
        FieldEval field = (FieldEval) createEvalTree(plan, blockName, like.getColumnRef());
        ConstEval pattern = (ConstEval) createEvalTree(plan, blockName, like.getPattern());
        return new LikeEval(like.isNot(), field, pattern);

      case InPredicate: {
        InPredicate inPredicate = (InPredicate) expr;
        FieldEval predicand =
            new FieldEval(plan.findColumn(blockName, (ColumnReferenceExpr) inPredicate.getPredicand()));
        RowConstant rowConstant = (RowConstant) createEvalTree(plan, blockName, inPredicate.getInValue());
        return new InEval(predicand, rowConstant, inPredicate.isNot());
      }

      case Is:
        break;

      case And:
      case Or:
      case Equals:
      case NotEquals:
      case LessThan:
      case LessThanOrEquals:
      case GreaterThan:
      case GreaterThanOrEquals:
      case Plus:
      case Minus:
      case Multiply:
      case Divide:
      case Modular:
        BinaryOperator bin = (BinaryOperator) expr;
        return new BinaryEval(exprTypeToEvalType(expr.getType()),
            createEvalTree(plan, blockName, bin.getLeft()),
            createEvalTree(plan, blockName, bin.getRight()));

      // others
      case Column:
        return createFieldEval(plan, blockName, (ColumnReferenceExpr) expr);

      case CountRowsFunction:
        FunctionDesc countRows = catalog.getFunction("count", new DataType[] {});

        try {
          plan.getBlock(blockName).setHasGrouping();

          return new AggFuncCallEval(countRows, (AggFunction) countRows.newInstance(),
              new EvalNode[] {});
        } catch (InternalException e) {
          throw new UndefinedFunctionException(CatalogUtil.
              getCanonicalName(countRows.getSignature(), new DataType[]{}));
        }

      case CountValueFunction:
      case Function:
        FunctionExpr function = (FunctionExpr) expr;
        // Given parameters
        Expr[] params = function.getParams();
        EvalNode[] givenArgs = new EvalNode[params.length];
        DataType[] paramTypes = new DataType[params.length];

        if (expr.getType() == OpType.CountValueFunction) {
          givenArgs[0] = createEvalTree(plan, blockName, params[0]);
          paramTypes[0] = CatalogUtil.newDataTypeWithoutLen(TajoDataTypes.Type.ANY);
        } else {
          for (int i = 0; i < params.length; i++) {
            givenArgs[i] = createEvalTree(plan, blockName, params[i]);
            paramTypes[i] = givenArgs[i].getValueType()[0];
          }
        }

        if (!catalog.containFunction(function.getSignature(), paramTypes)) {
            throw new UndefinedFunctionException(CatalogUtil.
                getCanonicalName(function.getSignature(), paramTypes));
        }

        FunctionDesc funcDesc = catalog.getFunction(function.getSignature(), paramTypes);

        try {
          if (funcDesc.getFuncType() == CatalogProtos.FunctionType.GENERAL)

            return new FuncCallEval(funcDesc,
                (GeneralFunction) funcDesc.newInstance(), givenArgs);
          else {
            plan.getBlock(blockName).setHasGrouping();
            return new AggFuncCallEval(funcDesc,
                (AggFunction) funcDesc.newInstance(), givenArgs);
          }
        } catch (InternalException e) {
          e.printStackTrace();
        }

      case CaseWhen:
        CaseWhenPredicate caseWhenExpr = (CaseWhenPredicate) expr;
        return createCaseWhenEval(plan, blockName, caseWhenExpr);

      case IsNullPredicate:
        IsNullPredicate nullPredicate = (IsNullPredicate) expr;
        return new IsNullEval(nullPredicate.isNot(),
            createFieldEval(plan, blockName, nullPredicate.getColumnRef()));

      default:
    }
    return null;
  }

  private FieldEval createFieldEval(LogicalPlan plan, String blockName,
                                    ColumnReferenceExpr columnRef) throws VerifyException {
    Column column;
    if (columnRef.hasTableName()) {
      column = plan.findColumnFromRelation(blockName, columnRef.getTableName(), columnRef.getName());
    } else {
      column = plan.suspectColumn(blockName, columnRef.getName());
    }
    return new FieldEval(column);
  }

  private static EvalType exprTypeToEvalType(OpType type) {
    switch (type) {
      case And: return EvalType.AND;
      case Or: return EvalType.OR;
      case Equals: return EvalType.EQUAL;
      case NotEquals: return EvalType.NOT_EQUAL;
      case LessThan: return EvalType.LTH;
      case LessThanOrEquals: return EvalType.LEQ;
      case GreaterThan: return EvalType.GTH;
      case GreaterThanOrEquals: return EvalType.GEQ;
      case Plus: return EvalType.PLUS;
      case Minus: return EvalType.MINUS;
      case Multiply: return EvalType.MULTIPLY;
      case Divide: return EvalType.DIVIDE;
      case Modular: return EvalType.MODULAR;
      case Column: return EvalType.FIELD;
      case Function: return EvalType.FUNCTION;
      default: throw new RuntimeException("Unsupported type: " + type);
    }
  }

  public CaseWhenEval createCaseWhenEval(LogicalPlan plan, String blockName,
                                              CaseWhenPredicate caseWhen) throws VerifyException {
    CaseWhenEval caseEval = new CaseWhenEval();
    EvalNode condition;
    EvalNode result;

    for (CaseWhenPredicate.WhenExpr when : caseWhen.getWhens()) {
      condition = createEvalTree(plan, blockName, when.getCondition());
      result = createEvalTree(plan, blockName, when.getResult());
      caseEval.addWhen(condition, result);
    }

    if (caseWhen.hasElseResult()) {
      caseEval.setElseResult(createEvalTree(plan, blockName, caseWhen.getElseResult()));
    }

    return caseEval;
  }

  Target[] annotateTargets(LogicalPlan plan, String blockName,
                                       org.apache.tajo.algebra.Target [] targets)
      throws VerifyException {
    Target annotatedTargets [] = new Target[targets.length];

    for (int i = 0; i < targets.length; i++) {
      annotatedTargets[i] = createTarget(plan, blockName, targets[i]);
    }
    return annotatedTargets;
  }

  Target createTarget(LogicalPlan plan, String blockId,
                             org.apache.tajo.algebra.Target target) throws VerifyException {
    if (target.hasAlias()) {
      return new Target(createEvalTree(plan, blockId, target.getExpr()),
          target.getAlias());
    } else {
      return new Target(createEvalTree(plan, blockId, target.getExpr()));
    }
  }

  /**
   * It transforms a list of targets to schema. If it contains anonymous targets, it names them.
   */
  static Schema getProjectedSchema(LogicalPlan plan, Target[] targets) {
    Schema projected = new Schema();
    for(Target t : targets) {
      DataType type = t.getEvalTree().getValueType()[0];
      String name;
      if (t.hasAlias()) {
        name = t.getAlias();
      } else if (t.getEvalTree().getName().equals("?")) {
        name = plan.newAnonymousColumnName();
      } else {
        name = t.getEvalTree().getName();
      }
      projected.addColumn(name,type);
    }

    return projected;
  }
}